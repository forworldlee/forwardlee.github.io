<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis数据灾备和恢复过程中踩到的雷]]></title>
    <url>%2F2018%2F05%2F28%2FRedis%E6%95%B0%E6%8D%AE%E7%81%BE%E5%A4%87%E5%92%8C%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%B8%A9%E5%88%B0%E7%9A%84%E9%9B%B7%2F</url>
    <content type="text"><![CDATA[生产环境配置策略RDB 生成快照的频率策略要在每分钟生成一次，但是有多少key发生变化可根据自身业务量配置。save 60 1000 AOF 在生产环境一定要打开，与RDB同时运行，fsync策略为everysec。 生产环境备份策略RDB主要做冷备，用craontab执行定时脚本，做数据备份。备份数据保留48小时，脚本清理48小时以前的数据。每天备份当日的数据，每天的数据保存一个月。把所有数据再备份到远程云服务器上。 每小时备份脚本 12345678#!/bin/bashcur_date=`date +%Y%m%d%H`rm -rf /var/redis/6379/bak/hour/$cur_datecp /var/redis/6379/dump.rdb /var/redis/6379/bak/hour/$cur_datepre_date=`date -d -48hour +%Y%m%d%H`rm -rf /var/redis/6379/bak/hour/$pre_date 每天备份 12345678#!/bin/bashcur_date=`date +%Y%m%d`rm -rf /var/redis/6379/bak/hour/$cur_datecp /var/redis/6379/dump.rdb /var/redis/6379/bak/dayli/$cur_datepre_date=`date -d -1month +%Y%m%d`rm -rf /var/redis/6379/bak/dayli/$pre_date 创建定时脚本crontab -e 123[root@eshop-cache01 dayli]# crontab -e0 * * * * sh /usr/local/redis/redis_rdb_data_bak_hour.sh0 0 * * * sh /usr/local/redis/redis_rdb_data_bak_dayli.sh 踩过雷后的数据恢复流程NO.1雷：我们理解的redis优先使用aof文件恢复数据，如果aof文件没有数据，应该从rdb恢复数据。【错】 原因：在redis配置文件中appendonly为yes，把备份数据拷贝到redis数据目录下，启动redis服务，并没有加载备份数据，而是优先加载了aof空数据，恢复失败。 NO.2雷：既然优先使用aof恢复数据，那么我们把aof文件删除掉，再启动redis服务，恢复rdb数据。【错】 原因：即使删除了aof文件，redis在启动时也会优先检查是否存在aof文件，如果没有则创建一个空的aof文件并加载空数据。恢复失败。 NO.3雷：把redis配置的appendonly设置为no，再恢复rdb数据，启动redis加载rdb数据后，再停掉redis，修改配置appendonly为yes，再启动redis，恢复数据。【错】 原因：配置appendonly为no，那么redis的appendonly.aof文件将失效，其中的数据也将不是正确的数据，恢复rdb数据后，再把appendonly修改为yes，此时再重启redis服务，redis将加载appendonly.aof的错误数据。恢复失败。 正确的数据恢复流程停止redis服务 1redis-cli SHUDOWN 修改redis配置vi /etc/redis/6379.conf 123...appendonly no... 删除aof文件 1rm -rf /var/redis/6379/appendonly.aof 拷贝最新一个小时的数据到redis目录下命名为dump.rdb 1cp /var/redis/6379/bak/2019052600 /var/redis/6379/dump.rdb 启动redis服务 12cd /etc/init.d/./redis_6379 start 热配置redis的appendonly为yes，这是最重要的一步。 123456[root@eshop-cache01 src]# redis-cli 127.0.0.1:6379&gt; config get appendonly1) &quot;appendonly&quot;2) &quot;no&quot;127.0.0.1:6379&gt; config set appendonly yesOK 停止redis服务 1redis-cli SHUDOWN 修改redis配置vi /etc/redis/6379.conf 123...appendonly yes... 启动redis服务 12cd /etc/init.d/./redis_6379 start]]></content>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化方式RDB和AOF比较应用]]></title>
    <url>%2F2018%2F05%2F25%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E5%BC%8FRDB%E5%92%8CAOF%E6%AF%94%E8%BE%83%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[RDB持久化方式的工作原理设定时间间隔t内有n次key的操作检查，就进行持久化。例如save 60 1000，每个60秒有1000个key发生变化，则进行持久化。RDB在做持久化时，保存完整的一份数据快照，旧的快照文件被覆盖。 RDB持久化方案的优点（1）持久化的时间间隔可以由redis控制，所以可以按照一定的时间间隔把数据快照文件拷贝出来，更好的支撑数据冷备份。（2）RDB持久化文件是Redis数据文件，在做redis故障恢复时，数据加载效率更高。（3）Redis数据操作都在内存中进行，效率高。（4）Redis会创建一个副本进程（fork）进行数据持久化，持久化过程中，对redis本身的数据操作影响较小。 RDB持久化方式的缺点（1）两次持久化操作的间隔时间内，Redis发生故障，那么将丢失这个时间内的所有数据。–重点（2）当两次持久化操作间隔时间较长，Redis内可能产生大量新的数据，生成数据快照文件时，可能导致Redis数据服务暂停数秒。 AOF持久化方式的工作原理设定一个AOF持久化文件大小，Redis每隔1秒进行一次append only的完整数据指令日志的写文件持久化操作，当AOF文件大小达到指定大小后，Redis会使用LRU算法淘汰无效数据，缩小数据大小，重新创建一个AOF文件，旧的AOF文件就会删除。AOF在做持久化时，保存的是完整数据的写指令日志数据。 PS:现代操作系统的写文件操作过程是，先将文件数据写入到系统os cache缓存层，当os cache内的数据达到一定量后，再写入磁盘。 AOF持久化方式的优点（1）数据持久化每秒钟进行一次，即使Redis发生故障，丢失的数据只是1秒钟的数据。–重点（2）数据持久化时，数据从os cache中写入磁盘时，文件不易破损，即使破损，redis有可用的工具进行修复。 AOF持久化方式的缺点（1）Redis数据操作每次都些人os cache中，要比直接写入内存效率有所降低，导致Redis的吞吐量QPS略有下降。（2）AOF文件的rewrite时机不可控，所以不容易实现数据备份。（3）持久化保存的是全量数据的写指令日志，并非Redis数据文件，在Redis启动加载数据时，效率低下。–重点 RDB和AOF持久化方式选择两种方式，各有优缺点。RDB效率更高，但是丢失数据量会比较大；AOF的数据要进行写文件操作，效率略低，但是保存的持久化数据更完整。在实际应用中，通常会同时选择两种方案。可用方案：实现Redis主从集群，主节点用AOF，保证数据更好的完整性，即使出现故障，也能从故障中恢复数据，虽然AOF方式的Redis数据QPS会下降，但影响不大；从节点用短时间间隔（秒级）的RDB，从节点对外不提供服务，这样从节点出现故障的几率就会大大降低，RDB方式能够很好的实现数据文件的备份。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.8 + MariaDB 10.0 with Galera Cluster+Keepalived高可用解决方案]]></title>
    <url>%2F2018%2F05%2F24%2FCentOS-6-8-MariaDB-10-0-with-Galera-Cluster-Keepalived%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[环境准备使用三台最小化安装的CentOS 6.8 x86_64新环境。 节点 节点名称 节点IP donor db1 192.168.1.150 node1 db2 192.168.1.151 node2 db3 192.168.1.152 Step 1- 设置MariaDB的yum安装源创建/etc/yum.repos.d/mariadb.repo CentOS 6 – 64bit系统mariadb.repo内容如下: 12345[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.0/centos6-amd64gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 For CentOS 6 – 32bit系统mariadb.repo内容如下: 12345[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.0/centos6-x86gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 Step 2 – 设置SELinux状态在开始安装之前，先把三台机器的SELinux状态设置为permissive，临时设置如下，重启失效。 1sudo setenforce 0 永久设置: 1vi /etc/selinux/config 12345678910# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced. default# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=permissive# SELINUXTYPE= can take one of these two values:# targeted - Targeted processes are protected,# mls - Multi Level Security protection.SELINUXTYPE=targeted Step 3 – 安装 MariaDB Galera Cluster 10.0使用yum安装MariaDB Galera Cluster，需要先安装socat工具包，用来确保yum可以找到安装源。CentOS 6用以下方式安装： 1sudo yum install -y http://dl.fedoraproject.org/pub/epel/6/x86_64/Packages/s/socat-1.7.2.3-1.el6.x86_64.rpm CentOS 7用以下方式安装： 1sudo yum install socat 开始安装数据库集群环境 1sudo yum install MariaDB-Galera-server MariaDB-client rsync galera Step 4: MariaDB安全性设置MariaDB是Mysql的一个分支，所以使用Mysql的命令启动数据库。 1sudo service mysql start 执行以下脚本，并按提示进行相应操作，提升数据库安全。设置root初始密码为。 1sudo /usr/bin/mysql_secure_installation 我把root用户密码设置为root。 Step 5 – 创建MariaDB Galera Cluster集群数据通信用户创建一个集群节点之间进行数据状态快照转移（State Transfer Snapshot – SST）所使用的用户账号。 1234567mysql -u root -pmysql&gt; DELETE FROM mysql.user WHERE user=&apos;&apos;;mysql&gt; GRANT ALL ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;dbpass&apos;;mysql&gt; GRANT USAGE ON *.* to galera@&apos;%&apos; IDENTIFIED BY &apos;galera&apos;;mysql&gt; GRANT ALL PRIVILEGES on *.* to galera@&apos;%&apos;;mysql&gt; FLUSH PRIVILEGES;mysql&gt; quit 在开发或测试环境中，使用%表示任意主机，也就是说允许root用户和galera用户可以从任意主机登访问数据库。出于安全考虑，你可以把%替换成你所允许的主机名称或者主机IP地址。 Step 6 – MariaDB Galera Cluster 集群配置停止Mysql服务 1sudo service mysql stop 先创建Donor节点的配置信息。Donor节点只用来同步数据，不能有外部链接操作Donor节点数据，保证Donor节点的健康状态，维护正常的集群运行状态。其他节点只需要修改wsrep_node_address=’192.168.1.150’和wsrep_node_name=’db1’两个配置即可，其他配置相同。 向/etc/my.cnf.d/server.cnf文件中添加以下配置信息: 1sudo cat &gt;&gt; /etc/my.cnf.d/servebinlog_format=ROW 123456789101112131415161718default-storage-engine=innodbinnodb_autoinc_lock_mode=2innodb_locks_unsafe_for_binlog=1query_cache_size=0query_cache_type=0bind-address=0.0.0.0datadir=/var/lib/mysqlinnodb_log_file_size=100Minnodb_file_per_tableinnodb_flush_log_at_trx_commit=2wsrep_provider=/usr/lib64/galera/libgalera_smm.sowsrep_cluster_address=&quot;gcomm://192.168.1.150,192.168.1.151,192.168.1.152&quot;wsrep_cluster_name=&apos;galera_cluster&apos;wsrep_node_address=&apos;192.168.1.150&apos;wsrep_node_name=&apos;db1&apos;wsrep_sst_method=rsyncwsrep_sst_auth=sst_user:dbpassEOF wsrep_cluster_address配置省略了默认端口4567。 其他两个节点所需要修改的配置： node1节点 : 12wsrep_node_address=&apos;192.168.1.151&apos;wsrep_node_name=&apos;db2&apos; node2节点 : 12wsrep_node_address=&apos;192.168.1.152&apos;wsrep_node_name=&apos;db3&apos; Step 7– 初始化Donor节点Donor节点是整个集群的优先初始化节点，只有Donor节点先启动，其他子节点才能正常加入到集群当中。启动Donor节点，需要配置‐‐wsrep-new-cluster参数。 1sudo /etc/init.d/mysql start --wsrep-new-cluster 运行以下命令，查看集群的运行状态。 1mysql -uroot -p -e&quot;show status like &apos;wsrep%&apos;&quot; 输出以下信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263+------------------------------+-----------------------------------------------+| Variable_name | Value |+------------------------------+-----------------------------------------------+| wsrep_local_state_uuid | 47b3fdaa-5f43-11e8-8cbd-62ce6e10f564 || wsrep_protocol_version | 8 || wsrep_last_committed | 2 || wsrep_replicated | 0 || wsrep_replicated_bytes | 0 || wsrep_repl_keys | 0 || wsrep_repl_keys_bytes | 0 || wsrep_repl_data_bytes | 0 || wsrep_repl_other_bytes | 0 || wsrep_received | 10 || wsrep_received_bytes | 2304 || wsrep_local_commits | 0 || wsrep_local_cert_failures | 0 || wsrep_local_replays | 0 || wsrep_local_send_queue | 0 || wsrep_local_send_queue_max | 1 || wsrep_local_send_queue_min | 0 || wsrep_local_send_queue_avg | 0.000000 || wsrep_local_recv_queue | 0 || wsrep_local_recv_queue_max | 2 || wsrep_local_recv_queue_min | 0 || wsrep_local_recv_queue_avg | 0.100000 || wsrep_local_cached_downto | 1 || wsrep_flow_control_paused_ns | 0 || wsrep_flow_control_paused | 0.000000 || wsrep_flow_control_sent | 0 || wsrep_flow_control_recv | 0 || wsrep_cert_deps_distance | 1.000000 || wsrep_apply_oooe | 0.000000 || wsrep_apply_oool | 0.000000 || wsrep_apply_window | 1.000000 || wsrep_commit_oooe | 0.000000 || wsrep_commit_oool | 0.000000 || wsrep_commit_window | 1.000000 || wsrep_local_state | 4 || wsrep_local_state_comment | Synced || wsrep_cert_index_size | 1 || wsrep_causal_reads | 0 || wsrep_cert_interval | 0.000000 || wsrep_incoming_addresses | 192.168.1.150:3306 || wsrep_desync_count | 0 || wsrep_evs_delayed | || wsrep_evs_evict_list | || wsrep_evs_repl_latency | 4.67e-06/9.14775e-06/1.1497e-05/2.63955e-06/4 || wsrep_evs_state | OPERATIONAL || wsrep_gcomm_uuid | 559ef6a3-5f45-11e8-92a5-52514b1a7147 || wsrep_cluster_conf_id | 7 || wsrep_cluster_size | 1 || wsrep_cluster_state_uuid | 47b3fdaa-5f43-11e8-8cbd-62ce6e10f564 || wsrep_cluster_status | Primary || wsrep_connected | ON || wsrep_local_bf_aborts | 0 || wsrep_local_index | 0 || wsrep_provider_name | Galera || wsrep_provider_vendor | Codership Oy &lt;info@codership.com&gt; || wsrep_provider_version | 25.3.23(r3789) || wsrep_ready | ON || wsrep_thread_count | 2 |+------------------------------+-----------------------------------------------+58 rows in set (0.00 sec) 重点查看这些信息是否正确：wsrep_cluster_size 当前集群中节点个数wsrep_local_state_comment 集群数据同步状态wsrep_incoming_addresses 数据提供方节点地址和端口wsrep_ready ON集群状态正常wsrep_connected ON集群连接状态正常 Step 8– 动态添加集群节点按照Step6的操作，配置node1和node2两个节点的配置文件，用以下命令启动集群子节点。注意与Donor节点的启动方式不同。 1sudo service mysql start 检查node1和node2两个节点的状态，是否正常。 1mysql -u root -p -e &quot;show status like &apos;wsrep%&apos;&quot; node1和node2两个子节点启动后，状态查询结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263+------------------------------+----------------------------------------------------------+| Variable_name | Value |+------------------------------+----------------------------------------------------------+| wsrep_local_state_uuid | 47b3fdaa-5f43-11e8-8cbd-62ce6e10f564 || wsrep_protocol_version | 8 || wsrep_last_committed | 2 || wsrep_replicated | 0 || wsrep_replicated_bytes | 0 || wsrep_repl_keys | 0 || wsrep_repl_keys_bytes | 0 || wsrep_repl_data_bytes | 0 || wsrep_repl_other_bytes | 0 || wsrep_received | 3 || wsrep_received_bytes | 476 || wsrep_local_commits | 0 || wsrep_local_cert_failures | 0 || wsrep_local_replays | 0 || wsrep_local_send_queue | 0 || wsrep_local_send_queue_max | 1 || wsrep_local_send_queue_min | 0 || wsrep_local_send_queue_avg | 0.000000 || wsrep_local_recv_queue | 0 || wsrep_local_recv_queue_max | 1 || wsrep_local_recv_queue_min | 0 || wsrep_local_recv_queue_avg | 0.000000 || wsrep_local_cached_downto | 18446744073709551615 || wsrep_flow_control_paused_ns | 0 || wsrep_flow_control_paused | 0.000000 || wsrep_flow_control_sent | 0 || wsrep_flow_control_recv | 0 || wsrep_cert_deps_distance | 0.000000 || wsrep_apply_oooe | 0.000000 || wsrep_apply_oool | 0.000000 || wsrep_apply_window | 0.000000 || wsrep_commit_oooe | 0.000000 || wsrep_commit_oool | 0.000000 || wsrep_commit_window | 0.000000 || wsrep_local_state | 4 || wsrep_local_state_comment | Synced || wsrep_cert_index_size | 0 || wsrep_causal_reads | 0 || wsrep_cert_interval | 0.000000 || wsrep_incoming_addresses | 192.168.1.151:3306,192.168.1.152:3306,192.168.1.150:3306 || wsrep_desync_count | 0 || wsrep_evs_delayed | || wsrep_evs_evict_list | || wsrep_evs_repl_latency | 0.00115351/0.00145445/0.0018473/0.000297523/4 || wsrep_evs_state | OPERATIONAL || wsrep_gcomm_uuid | 273a3916-5f4f-11e8-88db-8ab9682bb4ca || wsrep_cluster_conf_id | 9 || wsrep_cluster_size | 3 || wsrep_cluster_state_uuid | 47b3fdaa-5f43-11e8-8cbd-62ce6e10f564 || wsrep_cluster_status | Primary || wsrep_connected | ON || wsrep_local_bf_aborts | 0 || wsrep_local_index | 0 || wsrep_provider_name | Galera || wsrep_provider_vendor | Codership Oy &lt;info@codership.com&gt; || wsrep_provider_version | 25.3.23(r3789) || wsrep_ready | ON || wsrep_thread_count | 2 |+------------------------------+----------------------------------------------------------+58 rows in set (0.00 sec) Step 9 – 验证数据同步复制模拟场景1：集群中三个节点全部正常启动。在node1和node2两个节点分别创建库和表，查看donor节点是否正常的同步更新数据。 模拟场景2：node1和node2中的一个节点宕机。在没有宕机的节点（除donor节点）中进行数据CUD操作，先查看donor节点是否正常的同步更新数据，如果正常，则重新启动宕机节点，启动成功后，查看该节点能否正常的把不一致的数据同步过来。 PS:Galera在加入数据不一致的节点时，外部不能访问该节点，直到数据同步后才能访问该节点。 Keepalived实现MariaDB集群的高可用配请参考这篇文章《Keepalived HA +LVS+ Galera Cluster环境》]]></content>
      <tags>
        <tag>MariaDB</tag>
        <tag>Keepalived</tag>
        <tag>Galera</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Galera Cluster 3 + Mysql wresp 5.6安装配置]]></title>
    <url>%2F2018%2F05%2F24%2FGalera-Cluster-3-Mysql-wresp-5-6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装yum-builddep工具yum install yum-utils –enablerepo=extras]]></content>
      <tags>
        <tag>Galera</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived HA +LVS+ Galera Cluster环境]]></title>
    <url>%2F2018%2F05%2F23%2FKeepalived-HA-LVS-Galera-Cluster%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Galera Cluster实现Mysql集群，再配合Keepalived的VRRP和LVS实现Mysql集群的高可用和负载均衡。 开发环境CentOS 6.8 + Mysql Galera 5.5 + Keepalived 1.4.4 1.安装Keepalived 123yum -y install kernel-develyum -y install ipvsadm 命令号执行ipvsadm是否安装成功，如果可以执行，则说明已经安装。 123wget http://www.keepalived.org/software/keepalived-1.4.4.tar.gztar -zvxf keepalived-1.4.4.tar.gz 找到Linux的内核源码路径，不同版本的操作系统版本号不同。 /usr/src/kernels/2.6.32-696.30.1.el6.x86_64/ 安装到/usr/local/keepalived目录，安装LVS功能需要指定内容源码路径。 1./configure --prefix=/usr/local/keepalived --with-kernel-dir=/usr/src/kernels/2.6.32-696.30.1.el6.x86_64 执行结果 12345678910111213141516171819202122232425262728293031323334353637Keepalived configuration------------------------Keepalived version : 1.4.4Compiler : gccPreprocessor flags : -I/usr/src/kernels/2.6.32-696.30.1.el6.x86_64/includeCompiler flags : -Wall -Wunused -Wstrict-prototypes -Wextra -g -O2 -D_GNU_SOURCE -fPIELinker flags : -pieExtra Lib : -lcrypto -lssl Use IPVS Framework : YesIPVS use libnl : NoIPVS syncd attributes : NoIPVS 64 bit stats : Nofwmark socket support : YesUse VRRP Framework : YesUse VRRP VMAC : YesUse VRRP authentication : YesWith ip rules/routes : YesSNMP vrrp support : NoSNMP checker support : NoSNMP RFCv2 support : NoSNMP RFCv3 support : NoDBUS support : NoSHA1 support : NoUse Debug flags : Nosmtp-alert debugging : NoUse Json output : NoStacktrace support : NoMemory alloc check : Nolibnl version : NoneUse IPv4 devconf : NoUse libiptc : NoUse libipset : Noinit type : upstartBuild genhash : YesBuild documentation : No*** WARNING - this build will not support IPVS with IPv6. Please install libnl/libnl-3 dev libraries to support IPv6 with IPVS. 编译安装 1make &amp; make install 拷贝keepalived配置文件到/etc/keepalived/keepalived.conf 12345mkdir /etc/keepalivedcp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/cd /usr/local/keepalived/sbin/./keepalived 查看keepalived运行日志 1tail -f /var/log/messages 停止keepalived 1pkill keepalived 修改配置文件 1vi /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859! Configuration File for keepalived## 重点配置router_id LVS_150global_defs &#123; notification_email &#123;# admin@example.com &#125; # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 #smtp_connect_timeout 30 #router_id LVS_DEVEL #vrrp_skip_check_adv_addr #vrrp_strict #vrrp_garp_interval 0 #vrrp_gna_interval 0 router_id LVS_150&#125;##重点配置 虚拟路由节点virtual_router_id 51，主从配置：state MASTER/SLAVE，虚拟ip可以多个用多行表示：virtual_ipaddressvrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.200.16 &#125;&#125;##重点配置lb_algo wrr ，lb_kind DR，路由协议protocol TCP，真实IP和端口号real_server 192.168.1.150 3306，connect_port 3306virtual_server 192.168.200.16 3306 &#123; delay_loop 6 lb_algo wrr lb_kind DR persistence_timeout 50 protocol TCP real_server 192.168.1.150 3306 &#123; weight 5 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 3306 &#125; &#125; real_server 192.168.1.152 3306 &#123; weight 5 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 3306 &#125; &#125;&#125; 启动keepalived 1./keepalived 在虚拟IP对应的其他节点，按照上述同样的操作安装keepalived，环境准备完成后，可以通过虚拟IP访问mysql数据库。 1mysql -h 192.168.200.16 -ugalera -pgalera 后续问题：在Mysql Galera Cluster单点故障的恢复和重启。]]></content>
      <tags>
        <tag>Keepalived</tag>
        <tag>Galera</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.8+MySQL 5.5 with Galera Cluster环境搭建]]></title>
    <url>%2F2018%2F05%2F23%2FCentOS-6-8-MySQL-5-5-with-Galera-Cluster%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718##先安装依赖库yum install libaio gcc gcc-c++ boost-devel scons check-devel openssl-develln -sf /usr/lib64/libssl.so.10 /usr/lib64/libssl.so.6ln -sf /usr/lib64/libcrypto.so.10 /usr/lib64/libcrypto.so.6##下载MySQL with wsrep源码包，目前最新版本是5.5.34-25.9wget https://launchpad.net/codership-mysql/5.5/5.5.34-25.9/+download/mysql-5.5.34_wsrep_25.9-linux-x86_64.tar.gztar zxvf mysql-5.5*mv mysql-5.5.34_wsrep_25.9-linux-x86_64 /usr/local/mysqlcd /usr/local/mysql/groupadd mysqluseradd -r -g mysql mysqlchown -R mysql:mysql ../scripts/mysql_install_db --no-defaults --datadir=/opt/mysqldb/ --user=mysqlchown -R root .chown -R mysql /opt/mysqldb/echo &quot;export PATH=$PATH:/usr/local/mysql/bin&quot; &gt;&gt; /etc/profilesource /etc/profile[root@localhost mysql]# vi /etc/my.cnf [mysqld]datadir=/opt/mysqldbsocket = /tmp/mysql.sockuser=mysql symbolic-links=0 12345678910111213141516171819202122##启动Mysqlmysqld_safe --wsrep_cluster_address=gcomm:// &gt;/dev/null &amp;##安装Xtrabackupyum install perl-DBD-MySQL perl-Time-HiRes ncwget https://www.percona.com/downloads/XtraBackup/XtraBackup-2.1.9/RPM/rhel6/x86_64/percona-xtrabackup-2.1.9-744.rhel6.x86_64.rpmrpm -ivh percona-xtrabackup-2.1.9-744.rhel6.x86_64.rpm##安装Galera复制插件wget https://launchpad.net/galera/3.x/25.3.5/+download/galera-25.3.5-src.tar.gztar zxvf galera-25.3.5-src.tar.gzcd galera-25.3.5-srcsconscp garb/garbd /usr/local/mysql/bin/cp libgalera_smm.so /usr/local/mysql/lib/plugin/ mysql初始化配置 12345678910111213141516171819mkdir -p /var/lib/mysqlmkdir -p /etc/mysql/conf.d/chown mysql:mysql /var/lib/mysqlcp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql/usr/local/mysql/bin/mysqld_safe --wsrep_cluster_address=gcomm:// &gt;/dev/null &amp;##创建用于同步的帐号，注意替换掉示例值。mysql -e &quot;SET wsrep_on=OFF; GRANT ALL ON *.* TO &apos;galera&apos;@&apos;%&apos; IDENTIFIED BY &apos;galera&apos;&quot;;##我使用的mysql版本再执行上述授权语句后，%代表任意主机，却不包含localhost，所以要给防伪localhost单独授权。mysql -e &quot;SET wsrep_on=OFF; GRANT ALL ON *.* TO &apos;galera&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;galera&apos;&quot;;##修改root帐号密码，注意替换掉示例值。mysql -e &quot;SET wsrep_on=OFF;GRANT ALL PRIVILEGES ON * . * TO &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION MAX_QUERIES_PER_HOUR 0 MAX_CONNECTIONS_PER_HOUR 0 MAX_UPDATES_PER_HOUR 0 MAX_USER_CONNECTIONS 0 ; &quot;##查看授权mysql -uroot -proot;show grants for galera@&quot;%&quot;;show grants for galera@&quot;localhost&quot;;##关闭MySQLpkill mysql Galera集群配置 修改my.cnf 1vi /etc/my.cnf my.cnf配置： 12345678910111213141516171819202122232425262728293031[mysqld]datadir=/opt/mysqldbsocket = /tmp/mysql.sockuser=mysqlsymbolic-links=0######galera conf start########server-id=101wsrep_node_name = mysql1wsrep_provider = /usr/local/mysql/lib/plugin/libgalera_smm.sowsrep_sst_method = rsync#使用sst的用户和密码，这里如果开启，需要在mysql上创建该用户，并授予其足够的权限wsrep_sst_auth=galera:galera# 配置集群的所有节点wsrep_cluster_address=gcomm://192.168.1.150:4567,192.168.1.151:4567# 配置自己的ip:port，每个配置各不相同wsrep_node_address=192.168.1.150:4567default_storage_engine=InnoDBinnodb_autoinc_lock_mode=2innodb_locks_unsafe_for_binlog=1innodb_flush_log_at_trx_commit=1innodb_file_per_table=1binlog_format=ROWlog-bin=mysql-binrelay-log=mysql-relay-binlog-slave-updates=1#[mysqld_safe]#log-error=/var/lib/mysql/mysqld.log#pid-file=/var/lib/mysql/mysqld.pid 节点mysql1启动 1/usr/local/mysql/bin/mysqld_safe --wsrep_cluster_address=gcomm:// &gt;/dev/null &amp; 检查启动的端口，应该有3306和4567两个端口 12netstat -tunlp |grep 4567netstat -tunlp |grep 3306 在集群中添加新的节点，并执行启动脚本。 1/etc/init.d/mysql start PS：复制虚拟机，设置新IP 在新的虚拟机中修改ifconfig-eth0，设置IP为192.168.1.151，去掉UUID、MAC两个参数。 1vi /etc/sysconfig/network-scripts/ifcfg-eth0 重建路由 1rm -rf /etc/udev/rules.d/70-persistent-net.rules 重启虚拟机 1shutown -r now 测试网络 1ping 192.168.1.150]]></content>
      <tags>
        <tag>Galera</tag>
        <tag>CentOS</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Galera Cluster环境快速搭建]]></title>
    <url>%2F2018%2F05%2F22%2FDocker-Galera-Cluster%E7%8E%AF%E5%A2%83%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[使用Docker快速创建MariaDB（与MySql同源） Galera集群环境 Docker开发环境：MacOS High Sieera 10.13.2 (17C88)MariaDB Galera Cluster容器环境：CentOS 7.3 + MariaDB 10.1.23 1.执行Docker拉取镜像 docker pull mjstealey/mariadb-galera:10.1 2.下载测试脚本 123git clone https://github.com/mjstealey/mariadb-galera.gitcd mariadb-galera/ 下载好的代码中包括创建docker容器的脚本和测试脚本。 3.创建集群节点并执行测试语句 ./three-node-test.sh 命令执行过程中会创建三个节点，并且执行测试sql查看集群节点数据同步是否正确。测试通过后，可以使用后续命令分别操作三个节点的数据库。 4.查看已经运行的节点进程 docker container ls 输出结果 1234CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0a06b6789c1c mjstealey/mariadb-galera:10.1 &quot;/docker-entrypoint.…&quot; 58 seconds ago Up 59 seconds 0.0.0.0:32791-&gt;3306/tcp, 0.0.0.0:32790-&gt;4444/tcp, 0.0.0.0:32789-&gt;4567/tcp, 0.0.0.0:32788-&gt;4568/tcp galera-node-3c4e5eb6d2ba1 mjstealey/mariadb-galera:10.1 &quot;/docker-entrypoint.…&quot; About a minute ago Up About a minute 0.0.0.0:32787-&gt;3306/tcp, 0.0.0.0:32786-&gt;4444/tcp, 0.0.0.0:32785-&gt;4567/tcp, 0.0.0.0:32784-&gt;4568/tcp galera-node-2bf53b99d540c mjstealey/mariadb-galera:10.1 &quot;/docker-entrypoint.…&quot; About a minute ago Up About a minute 0.0.0.0:32783-&gt;3306/tcp, 0.0.0.0:32782-&gt;4444/tcp, 0.0.0.0:32781-&gt;4567/tcp, 0.0.0.0:32780-&gt;4568/tcp galera-node-1 5.单独进入节点操作数据库docker exec -it bf53b99d540c mysql -uroot -ptemppassword MariaDB数据库的root用户密码是Docker在创建容器的时候配置的，可以从Dockerfile中找到配置，直接从镜像中拉取的容器镜像，是已经配置好的。如果本地执行Docker容器创建，那么可以修改Dockerfile中的相关配置。 命令中bf53b99d540c是指容器进程的CONTAINER ID的值。 参数解释-i 可交互-t 分配终端 命令执行完会进入MariaDB的命令行交互窗口。 6.在任一一个节点操作数据库，数据都会在其他节点同步（接近同步）更新。==Galera规则要求创建的表必须要有主键，没有主键也要指定自增列。== 12345create table tbl_user( pkid int auto_increment primary key, username varchar(255) not null);]]></content>
      <tags>
        <tag>MariaDB</tag>
        <tag>Galera</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql分区操作（三）]]></title>
    <url>%2F2018%2F05%2F17%2FMySql%E5%88%86%E5%8C%BA%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[子分区操作常用RANGE和HASH复合分区实现子分区 1234567891011121314151617CREATE TABLE myblog.tbl_users_2 ( `pkid` INT NOT NULL , `username` VARCHAR(255) NOT NULL, `password` VARCHAR(255) NOT NULL, `email` VARCHAR(255) NULL, `sex` CHAR(1) NULL, `create_time` DATE NULL)ENGINE = InnoDBDEFAULT CHARACTER SET = utf8 PARTITION BY RANGE(YEAR(create_time))SUBPARTITION BY HASH(TO_DAYS(create_time))SUBPARTITIONS 2(PARTITION p0 VALUES LESS THAN (2010),PARTITION p1 VALUES LESS THAN (2017),PARTITION p2 VALUES LESS THAN (MAXVALUE)); 123INSERT INTO TBL_USERS_2 VALUES (1,&apos;1&apos;,&apos;1&apos;,&apos;1&apos;,1,&apos;2009-08-08&apos;);INSERT INTO TBL_USERS_2 VALUES (2,&apos;1&apos;,&apos;1&apos;,&apos;1&apos;,1,&apos;2016-08-07&apos;);INSERT INTO TBL_USERS_2 VALUES (3,&apos;1&apos;,&apos;1&apos;,&apos;1&apos;,1,&apos;2018-08-08&apos;); 查看产生的分区 123456789101112131415161718EXPLAIN PARTITIONS SELECT * FROM tbl_users_2 \G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tbl_users_2 partitions: p0_p0sp0,p0_p0sp1,p1_p1sp0,p1_p1sp1,p2_p2sp0,p2_p2sp1 type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 3 filtered: 100.00 Extra: NULL1 row in set, 2 warnings (0.00 sec)ERROR: No query specified 查看其中一条数据所在分区 123456789101112131415EXPLAIN PARTITIONS SELECT * FROM tbl_users_2 where create_time = &apos;2017-08-07&apos;\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tbl_users_2 partitions: p2_p2sp1 type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 1 filtered: 100.00 Extra: Using where1 row in set, 2 warnings (0.00 sec) 分区字段特殊性 按字段分区的字段不能为NULL，所以在建表时需要指定分区字段为NOT NULL。 分区管理 删除分区和分区上的数据 1alter table tbl_user drop partiton p0; 增加分区对于RANGE分区，只能添加比已经存在的分区范围更大的值。1alter table tbl_user add partition ( partition p0 values less than (100)); 对于LIST分区，只能添加不存在与分区列表中的值。 1alter table tbl_user add partition ( partition p0 values in (100,101,102)); 也就是说，100，101，102不在已定义的LIST分区内。 不丢失数据修改分区 如果原来的分区是这样的： 123456789create table tbl_user( pkid int not null, name varchar(255) ) partition by range(pkid) partitions 3( partition p0 values less than(100), partition p1 values less than(200), partition p2 values less than(300) ); ==修改(拆分)分区：== 1234alter table tbl_user reorganize partition p0 into ( partition s0 values less than(50), partition s1 values less than(100) ); 相当于原来的分区是这样创建的： 12345678910create table tbl_user( pkid int not null, name varchar(255) ) partition by range(pkid) partitions 4( partition s0 values less than(50), partition s1 values less than(100), partition p1 values less than(200), partition p2 values less than(300) ); LIST分区修改（拆分）同理。==修改(合并)分区：== 123alter table tbl_user reorganize partition s0,s1 into ( partition p0 values less than(100) ); 删除分区，不删除数据 1alter table tbl_user remove partitioning HASH和KEY分区管理 在没有数据的时候进行修改分区操作是可以的，如果在数据存在后再减少和增加分区，数据分布就不均匀了。 减少n个分区 1alter table tbl_user coalesce partition 2; 增加n个分区 1alter table tbl_user add partition 2; 其他分区管理语句 重建分区 1alter table tbl_user rebuild partition p0,p1,p2,p3; 优化分区(包括分析、检查、修补分区） 1alter table tbl_user optimize partition p0,p1,p2,p3; 分析分区 1alter table tbl_user analyze partiton p0,p1,p2,p3; 检查分区 1alter table tbl_user check partition p0,p1,p2,p3; 修补分区 1alter table tbl_user repair partition p0,p1,p2,p3; 其他细节 分区数最大不超过1024个，实际应用中分区数不超过150个；如果有唯一索引或者主键，分区列必须包含所有的唯一索引或者主键；不支持外键；不支持全区索引；常用日期进行分区；临时表不能被分区；单条数据查询分区管理意义不大，除非指定数据所在分区；计算分区成本，因为每次插入数据都会进行分区计算，分区函数不能过于复杂；分区字段不能为NULL；]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql分区操作（二）]]></title>
    <url>%2F2018%2F05%2F17%2FMySql%E5%88%86%E5%8C%BA%E6%93%8D%E4%BD%9C%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[【转自】https://blog.csdn.net/tjcyjd/article/details/11194489HASH分区和线性LINEAR HASH分区 123456789CREATE TABLE `myblog`.`tbl_user_friends_linear_hash` ( `pkid` INT NOT NULL AUTO_INCREMENT, `user_id` INT NOT NULL, `friend_id` INT NOT NULL, `create_time` DATETIME NOT NULL, PRIMARY KEY (`pkid`))ENGINE = InnoDBDEFAULT CHARACTER SET = utf8COMMENT = &apos;用户好友&apos; PARTITION BY LINEAR HASH(pkid) PARTITIONS 3 ; MySQL还支持线性哈希功能，它与常规哈希的区别在于，线性哈希功能使用的一个线性的2的幂（powers-of-two）运算法则，而常规 哈希使用的是求哈希函数值的模数。 线性哈希分区和常规哈希分区在语法上的唯一区别在于，在“PARTITION BY” 子句中添加“LINEAR”关键字，如下面所示： 1234567891011CREATE TABLE employees ( id INT NOT NULL, fname VARCHAR(30), lname VARCHAR(30), hired DATE NOT NULL DEFAULT &apos;1970-01-01&apos;, separated DATE NOT NULL DEFAULT &apos;9999-12-31&apos;, job_code INT, store_id INT)PARTITION BY LINEAR HASH(YEAR(hired))PARTITIONS 4； 假设一个表达式expr, 当使用线性哈希功能时，记录将要保存到的分区是num 个分区中的分区N，其中N是根据下面的算法得到： 找到下一个大于num.的、2的幂，我们把这个值称为V ，它可以通过下面的公式得到： V = POWER(2, CEILING(LOG(2, num)))（例如，假定num是13。那么LOG(2,13)就是3.7004397181411。 CEILING(3.7004397181411)就是4，则V = POWER(2,4), 即等于16）。 设置 N = F(column_list) &amp; (V - 1). 当 N &gt;= num: · 设置 V = CEIL(V / 2) · 设置 N = N &amp; (V - 1) 例如，假设表t1，使用线性哈希分区且有4个分区，是通过下面的语句创建的： 123CREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATE) PARTITION BY LINEAR HASH( YEAR(col3) ) PARTITIONS 6; 现在假设要插入两行记录到表t1中，其中一条记录col3列值为’2003-04-14’，另一条记录col3列值为’1998-10-19’。第一条记录将要保存到的分区确定如下： V = POWER(2, CEILING(LOG(2,7))) = 8N = YEAR(‘2003-04-14’) &amp; (8 - 1) = 2003 &amp; 7 = 3 (3 &gt;= 6 为假（FALSE）: 记录将被保存到#3号分区中)第二条记录将要保存到的分区序号计算如下： V = 8N = YEAR(‘1998-10-19’) &amp; (8-1) = 1998 &amp; 7 = 6 (6 &gt;= 4 为真（TRUE）: 还需要附加的步骤) N = 6 &amp; CEILING(5 / 2) = 6 &amp; 3 = 2 (2 &gt;= 4 为假（FALSE）: 记录将被保存到#2分区中)按照线性哈希分区的优点在于增加、删除、合并和拆分分区将变得更加快捷，有利于处理含有极其大量（1000吉）数据的表。它的缺点在于，与使用常规HASH分区得到的数据分布相比，各个分区间数据的分布不大可能均衡。 KEY分区和LINEAR KEY分区 123456789CREATE TABLE `myblog`.`tbl_user_friends_linear_key` ( `pkid` INT NOT NULL AUTO_INCREMENT, `user_id` INT NOT NULL, `friend_id` INT NOT NULL, `create_time` DATETIME NOT NULL, primary key(pkid))ENGINE = InnoDBDEFAULT CHARACTER SET = utf8COMMENT = &apos;用户好友&apos; PARTITION BY LINEAR KEY(pkid) PARTITIONS 3 ; 按照KEY进行分区类似于按照HASH分区，除了HASH分区使用的用户定义的表达式，而KEY分区的 哈希函数是由MySQL 服务器提供。MySQL 簇（Cluster）使用函数MD5()来实现KEY分区；对于使用其他存储引擎的表，服务器使用其自己内部的 哈希函数，这些函数是基于与PASSWORD()一样的运算法则。 “CREATE TABLE … PARTITION BY KEY”的语法规则类似于创建一个通过HASH分区的表的规则。它们唯一的区别在于使用的关键字是KEY而不是HASH，并且KEY分区只采用一个或多个列名的一个列表。 通过线性KEY分割一个表也是可能的。下面是一个简单的例子： 1234567CREATE TABLE tk ( col1 INT NOT NULL, col2 CHAR(5), col3 DATE) PARTITION BY LINEAR KEY (col1)PARTITIONS 3; 在KEY分区中使用关键字LINEAR和在HASH分区中使用具有同样的作用，分区的编号是通过2的幂（powers-of-two）算法得到，而不是通过模数算法。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为未来而学]]></title>
    <url>%2F2018%2F05%2F16%2F%E4%B8%BA%E6%9C%AA%E6%9D%A5%E8%80%8C%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[123如果一个人只满足于完成别人所要求的事情，那么，他只能是个奴隶，只有当他超越了这个限度，才会成为一个自由人。——哈佛学习格言 有关学习的两个困境 一、学习是一场竞赛，我们凭什么才可以胜出？ 大城市里面人们为了能够上一所“好的”小学，要选择购置学区房； 大城市里面为了能够将来上好的中学，还要报各种课外班，什么奥数，英语，绘画，书法，钢琴，足球，篮球······； 大城市里面孩子们每天不是在上学就是在上课外班，家长不是在送孩子去上学的路上就是在送孩子去课外班的路上。 这一切正常吗，我们是选择了随大流还是经过了深思熟虑的思考？这样的学习方式和节奏是最有效的吗？这场学习的竞赛普通的家庭有竞争优势吗？哪些能力在我们未来会让我们更有竞争优势呢？哪些方面的学习对我们一生更加重要呢？ 不知道这些问题，朋友们有没有问过自己，有没有过深入的思考，有没有给自己一个答案。 与此相反的是，小城市、农村、郊区的孩子们多数情况是玩玩玩，大好的青春真的就在玩耍中渡过啦，想必长大后会后悔吧。毕竟，人生中有许多事情是需要时间的积累的，而时间是不可以购买的，时间是一去不复返的，错过真的很难弥补上。阅读，就属于这样的事情。 现在，城市与郊区的教育，重点学校与普通学校之间教育的差距越来越大，这种差距一方面体现在对教育的认知上，另一方面体现在优质的教育资源和用钱堆出来的课外兴趣班、优培班。 好在，我们还有一种方法，能够缩小这种无法改变的学习资源和环境差距。是什么样的方法呢？ 俗话说，要用正确的方法做正确的事情。这一点最关键。我们要从学习的最根本出发，去探寻学习的本质，去掌握学习的方法，去洞察未来，这就是我们需要做的最正确的事情，它保证我们走在一条正确的道路上。而做这些事情，好的学校和富裕的家庭条件都不是必须的条件，需要的是我们的态度和行动。 二、学习是为了生活，生活是一辈子的事情，我们是否有终身学习的准备？ 先不说，终身学习，就是学校里的学习，我们都无法很好地完成。这是为什么呢？ 说不爱学习的人，实际是没有发现好的学习方式、引人入胜的学习资源、让人体会到收获和成就感的学习成果。甚至，从更根本上来说，是没有找到或发现学习的意义。 其实，人天生就是学习的好手，不仅具有好奇心，而且也爱学习。 学习中往往会： 因为不知道自己不知道，而没有思考； 因为不知道学习目标是什么，不知道为什么而学，而没有动力； 因为不知道学习方法，而无法采取行动； 因为不知道学习需要经历的过程，而无法坚持。 在这里，你将看清楚“学习”的样子，看清楚“学习的过程”，掌握“学习”的方法，知道并体会到“学习”带来的各种机会和可能性。 从此，你会亲手为自己打开一扇通往未来的希望之门，你会走在通往未来的道路上，而且还站在巨人的肩膀上。慢慢地，你会发现你已经不是原来的你了，你能看的更远，也能看的更加清晰。终身学习也因此成为了你生活中形影不离的朋友！]]></content>
      <tags>
        <tag>学习力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql分区操作（一）]]></title>
    <url>%2F2018%2F05%2F16%2FMySql%E5%88%86%E5%8C%BA%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[##分区类型RANGE 连续的列值区间分区，有主键和唯一键必须使用，如果没有则可以指定任何一列；LIST 类似RANGE分区，区别在于指定一系列的列值作为分区条件；HASH 由函数表达式返回值决定所在分区，函数返回值必须为非负整数；KEY 由mysql提供的HASH函数进行服务，==使用较少==。 ##创建表分区 1234567891011121314CREATE TABLE tbl_users ( `pkid` INT NOT NULL AUTO_INCREMENT, `username` VARCHAR(255) NOT NULL, `password` VARCHAR(255) NOT NULL, `email` VARCHAR(255) NULL, `sex` CHAR(1) NULL, PRIMARY KEY (`pkid`))ENGINE = InnoDBDEFAULT CHARACTER SET = utf8 PARTITION BY RANGE(pkid) PARTITIONS 3( PARTITION part0 VALUES LESS THAN (10000), PARTITION part1 VALUES LESS THAN (20000), PARTITION part2 VALUES LESS THAN (MAXVALUE)) ; ##查看分区 1select * from information_schema.partitions where table_schema=&apos;myblog&apos; and table_name=&apos;tbl_users&apos; \G; 得到如下结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879*************************** 1. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: myblog TABLE_NAME: tbl_users PARTITION_NAME: part0 SUBPARTITION_NAME: NULL PARTITION_ORDINAL_POSITION: 1SUBPARTITION_ORDINAL_POSITION: NULL PARTITION_METHOD: RANGE SUBPARTITION_METHOD: NULL PARTITION_EXPRESSION: pkid SUBPARTITION_EXPRESSION: NULL PARTITION_DESCRIPTION: 10000 TABLE_ROWS: 0 AVG_ROW_LENGTH: 0 DATA_LENGTH: 16384 MAX_DATA_LENGTH: NULL INDEX_LENGTH: 0 DATA_FREE: 0 CREATE_TIME: 2018-05-16 18:21:08 UPDATE_TIME: NULL CHECK_TIME: NULL CHECKSUM: NULL PARTITION_COMMENT: NODEGROUP: default TABLESPACE_NAME: NULL*************************** 2. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: myblog TABLE_NAME: tbl_users PARTITION_NAME: part1 SUBPARTITION_NAME: NULL PARTITION_ORDINAL_POSITION: 2SUBPARTITION_ORDINAL_POSITION: NULL PARTITION_METHOD: RANGE SUBPARTITION_METHOD: NULL PARTITION_EXPRESSION: pkid SUBPARTITION_EXPRESSION: NULL PARTITION_DESCRIPTION: 20000 TABLE_ROWS: 0 AVG_ROW_LENGTH: 0 DATA_LENGTH: 16384 MAX_DATA_LENGTH: NULL INDEX_LENGTH: 0 DATA_FREE: 0 CREATE_TIME: 2018-05-16 18:21:08 UPDATE_TIME: NULL CHECK_TIME: NULL CHECKSUM: NULL PARTITION_COMMENT: NODEGROUP: default TABLESPACE_NAME: NULL*************************** 3. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: myblog TABLE_NAME: tbl_users PARTITION_NAME: part2 SUBPARTITION_NAME: NULL PARTITION_ORDINAL_POSITION: 3SUBPARTITION_ORDINAL_POSITION: NULL PARTITION_METHOD: RANGE SUBPARTITION_METHOD: NULL PARTITION_EXPRESSION: pkid SUBPARTITION_EXPRESSION: NULL PARTITION_DESCRIPTION: MAXVALUE TABLE_ROWS: 0 AVG_ROW_LENGTH: 0 DATA_LENGTH: 16384 MAX_DATA_LENGTH: NULL INDEX_LENGTH: 0 DATA_FREE: 0 CREATE_TIME: 2018-05-16 18:21:08 UPDATE_TIME: NULL CHECK_TIME: NULL CHECKSUM: NULL PARTITION_COMMENT: NODEGROUP: default TABLESPACE_NAME: NULL3 rows in set (0.01 sec) ##查看分区上的数据 1select * from tbl_users partition(p0) ##查看分区数据查询性能 1explain partitions select * from tbl_users where pkid =2; ##其他分区类型LIST类型 12345678910111213CREATE TABLE `myblog`.`tbl_blog` ( `pkid` INT NOT NULL AUTO_INCREMENT, `title` VARCHAR(255) NOT NULL, `content` VARCHAR(5000) NULL, `create_time` DATETIME NULL, PRIMARY KEY (`pkid`))ENGINE = InnoDBDEFAULT CHARACTER SET = utf8COMMENT = &apos;博客文章&apos; PARTITION BY LIST(pkid) PARTITIONS 3( PARTITION part0 VALUES IN (1,2,3), PARTITION part1 VALUES IN (4,5,6), PARTITION part2 VALUES IN (7,8,9)) ; HASH类型利用分区字段除分区数量取余数，就把数据放到第余数个分区上。 123456789CREATE TABLE `myblog`.`tbl_user_friends` ( `pkid` INT NOT NULL AUTO_INCREMENT, `user_id` INT NOT NULL, `friend_id` INT NOT NULL, `create_time` DATETIME NOT NULL, PRIMARY KEY (`pki`))ENGINE = InnoDBDEFAULT CHARACTER SET = utf8COMMENT = &apos;用户好友&apos; PARTITION BY HASH(pkid) PARTITIONS 3 ; 插入数据 12insert into tbl_user_friends values(1,2,3,NULL);insert into tbl_user_friends values(5,2,3,NULL); 得到结论 1234567891011121314select * from tbl_user_friends partition(p1);+------+---------+-----------+-------------+| pkid | user_id | friend_id | create_time |+------+---------+-----------+-------------+| 1 | 2 | 3 | NULL |+------+---------+-----------+-------------+1 row in set (0.00 sec)mysql&gt; select * from tbl_user_friends partition(p2);+------+---------+-----------+-------------+| pkid | user_id | friend_id | create_time |+------+---------+-----------+-------------+| 5 | 2 | 3 | NULL |+------+---------+-----------+-------------+1 row in set (0.00 sec)]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDKBlockingQueue使用]]></title>
    <url>%2F2018%2F05%2F10%2FJDKBlockingQueue%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package cn.klxx.multithread;import org.junit.Test;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.LinkedBlockingDeque;import java.util.concurrent.PriorityBlockingQueue;import java.util.concurrent.SynchronousQueue;/** * @description JDK实现的阻塞和无阻塞队列测试 * @author ForwardLee */public class JDKBlockingQueueTest &#123; /** * 有界阻塞队列 */ @Test public void testArrayBlockingQueue() throws Exception &#123; ArrayBlockingQueue&lt;String&gt; arrayBlockingQueue = new ArrayBlockingQueue&lt;String&gt;(5); arrayBlockingQueue.add(&quot;a&quot;); arrayBlockingQueue.add(&quot;b&quot;); arrayBlockingQueue.add(&quot;c&quot;); arrayBlockingQueue.add(&quot;d&quot;); arrayBlockingQueue.add(&quot;e&quot;); arrayBlockingQueue.add(&quot;f&quot;); &#125; /** * @descripiton 可以是有界阻塞队列，也可以是无解阻塞队列，关键看实例化队列对象用的构造方法是否初始化队列大小 */ @Test public void testLinkedBlockingDeque() throws Exception &#123; LinkedBlockingDeque&lt;String&gt; linkedBlockingDeque = new LinkedBlockingDeque&lt;String&gt;();//new LinkedBlockingDeque&lt;String&gt;(2) linkedBlockingDeque.add(&quot;a&quot;); linkedBlockingDeque.offer(&quot;b&quot;); linkedBlockingDeque.add(&quot;c&quot; ); &#125; /** * @description 同步阻塞队列，主要应用场景在于多线程之间的线程切换，例如线程池的实现。 * 不能直接往队列中存数据。要往队列中存数据，前提是必须要有一个线程等待取数据 * Executors.newCachedThreadPool() * * Creates a thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available, and uses the provided * ThreadFactory to create new threads when needed. * &#123;@param threadFactory the factory to use when creating new threads * @return the newly created thread pool * @throws NullPointerException if threadFactory is null&#125; * * public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; * return new ThreadPoolExecutor(0, Integer.MAX_VALUE, * 60L, TimeUnit.SECONDS, * new SynchronousQueue&lt;Runnable&gt;(), * threadFactory); * &#125; */ @Test public void testSynchronousQueue() throws Exception &#123; final SynchronousQueue&lt;String&gt; synchronousQueue = new SynchronousQueue&lt;String&gt;(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; String peek = synchronousQueue.take(); System.out.println(peek); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; public void run() &#123; synchronousQueue.add(&quot;a&quot;); &#125; &#125;).start(); &#125; /** * PriorityBlockingQueue是带优先级的无界阻塞队列，每次出队都返回优先级最高的元素， * 是二叉树最小堆的实现，研究过数组方式存放最小堆节点的都知道，直接遍历队列元素是无序的。 * 队列存储的对象必须实现Comparable接口 * @throws Exception */ @Test public void testPriorityBlockingQueue() throws Exception &#123; PriorityBlockingQueue&lt;ObjectWithComparable&gt; priorityBlockingQueue= new PriorityBlockingQueue&lt;ObjectWithComparable&gt;(); ObjectWithComparable o1 = new ObjectWithComparable(); o1.setId(3); priorityBlockingQueue.add(o1); ObjectWithComparable o2 = new ObjectWithComparable(); o2.setId(4); priorityBlockingQueue.add(o2); ObjectWithComparable o3 = new ObjectWithComparable(); o3.setId(2); priorityBlockingQueue.add(o3); for (ObjectWithComparable objectWithComparable : priorityBlockingQueue) &#123; System.out.println(priorityBlockingQueue.take()); &#125; &#125; private class ObjectWithComparable implements Comparable&lt;ObjectWithComparable&gt;&#123; private int id; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Override public int compareTo(ObjectWithComparable o) &#123; return this.id&gt;o.id? 1:(this.id&lt;o.id? -1:0); &#125; @Override public String toString() &#123; return &quot;ObjectWithComparable&#123;&quot; + &quot;id=&quot; + id + &apos;&#125;&apos;; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>MultiThread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用wait(),notify()配合synchronized实现自定义阻塞队列MyBlockingQueue]]></title>
    <url>%2F2018%2F05%2F09%2F%E4%BD%BF%E7%94%A8wait-notify-%E9%85%8D%E5%90%88synchronized%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97MyBlockingQueue%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package cn.klxx.multithread;import java.util.LinkedList;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;/** * @author ForwardLee * @description 使用synchronized关键字，wait()和notify()方法实现阻塞队列 */public class MyBlockingQueue &#123; //队列容器 private final LinkedList&lt;Object&gt; list = new LinkedList&lt;Object&gt;(); //队列大小,使用AtomicInteger可以保证在多线程获取队列大小时线程安全 private AtomicInteger count = new AtomicInteger(0); //队列最大长度 private int maxSize; //队列最小长度 private int minSize = 0; //实现业务模型的锁 private Object lock = new Object(); public MyBlockingQueue(int length)&#123; this.maxSize = length; &#125; /** * @description 队列存数据 * @param obj */ public void putObj(Object obj)&#123; synchronized (lock)&#123; if (count.get()==maxSize) &#123; try &#123; lock.wait();//队列长度已经达到最大值，不能再继续存储数据，则线程处于等待状态，直至队列收到有可用位置的通知。 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; list.push(obj); count.incrementAndGet(); lock.notify();//如果已经有线程等待获取队列数据，此时就通知取数据线程有数据了。 System.out.println(&quot;存入对象：&quot;+obj); &#125; &#125; /** * @description 获取队列中的数据 * @return 返回队列的第一个元素 */ public Object getObject()&#123; Object retVal = null; synchronized (lock)&#123; if (count.get()==0) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; retVal = list.getFirst(); count.decrementAndGet(); lock.notify();//队列长度小于maxSize了，有存储空间了，就通知存储线程可以放入数据了。 System.out.println(&quot;取出对象：&quot;+retVal); &#125; return retVal; &#125; public static void main(String[] args) &#123; final MyBlockingQueue myBlockingQuene = new MyBlockingQueue(5); new Thread(new Runnable() &#123; @Override public void run() &#123; Object var1 = myBlockingQuene.getObject(); &#125; &#125;,&quot;t1&quot;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; myBlockingQuene.putObj(&quot;abc1&quot;); myBlockingQuene.putObj(&quot;abc2&quot;); myBlockingQuene.putObj(&quot;abc3&quot;); myBlockingQuene.putObj(&quot;abc4&quot;); myBlockingQuene.putObj(&quot;abc5&quot;); myBlockingQuene.putObj(&quot;abc6&quot;); System.out.println(&quot;此时队列长度L1=&quot;+myBlockingQuene.count.get()); myBlockingQuene.putObj(&quot;abc7&quot;);//这个对象放不了，线程就处于等待状态了。 &#125; &#125;,&quot;t2&quot;).start(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; Object var2 = myBlockingQuene.getObject();//t2线程中的abc7对象此时才能放入队列。 System.out.println(&quot;此时队列长度L2=&quot;+myBlockingQuene.count.get()); &#125; &#125;,&quot;t3&quot;).start(); &#125;&#125;]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CountDownLatch多线程性能]]></title>
    <url>%2F2018%2F05%2F08%2Fjava%2FCountDownLatch%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[cn.klxx.multithread;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;/** * Object方法wait()、notify()两个方法需要配合sychronized关键字使用， * wait()方法释放锁，notify()方法占有锁，所以要先调用wait()方法，再调用notify()方法 */public class MyCountDownLatch &#123;static List list = new ArrayList();public void addString(String a)&#123; list.add(a); System.out.println(&quot;list add string!&quot;);&#125;public int getSize()&#123; return list.size();&#125;static final Object lock = new Object(); public static void main(String[] args) &#123; final MyCountDownLatch myCountDownLatch = new MyCountDownLatch(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronized (lock)&#123; for (int i = 0; i &lt; 10; i++) &#123; myCountDownLatch.addString(&quot;abc&quot;); Thread.sleep(500); if(list.size()==5)&#123; lock.notify(); System.out.println(&quot;发出通知...&quot;); &#125; &#125; System.out.println(&quot;执行完这句话释放锁...&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;t1&quot;) ; Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronized (lock) &#123; if (list.size()!=5) &#123; lock.wait();//此时t2处于等待中，不再继续往下执行代码，直到收到通知才继续执行 &#125; System.out.println(&quot;t2 收到停止通知&quot;); throw new RuntimeException(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;t2&quot;) ; /** * t2必须先启动，因为wait方法不会占有锁，不影响t1执行；如果t1先启动会占有锁，而t2则不能使用锁无法执行。 * 用wait和notify配合关键字sychronized关键字，使用等notify所在的sychronized关键字代码块执行完， * wait所在的sychronized代码块才会继续执行，这样的最大问题就是收到通知的时间严重滞后于发送通知的时间。 * 所以要借助CountDownLatch来解决这个问题，CountDownLatch使用countDown方法发送完通知后也会继续执行， * 但是await方法会马上收到通知继续执行代码，避免了收到通知的严重滞后问题。 */ t2.start(); t1.start(); try &#123; Thread.sleep(10000); list.clear(); System.out.println(&quot;-----------------------------&quot;); System.out.println(&quot;list.size:&quot;+list.size()); System.out.println(&quot;-----------------------------&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; final CountDownLatch countDownLatch = new CountDownLatch(1); Thread t3 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; list.add(&quot;abc&quot;); System.out.println(&quot;list add string!&quot;); Thread.sleep(500); if (list.size()==5) &#123; System.out.println(&quot;发送通知&quot;); countDownLatch.countDown(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, &quot;t3&quot;); Thread t4 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; if (list.size()!=5) &#123; System.out.println(&quot;t4 等待...&quot;); countDownLatch.await(); &#125; System.out.println(&quot;list.size:&quot;+list.size()+&quot; ,t4 停止&quot;); throw new RuntimeException(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, &quot;t4&quot;); t3.start(); t4.start(); &#125;&#125;]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>MultiThread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 5.x进阶笔记（二）]]></title>
    <url>%2F2017%2F08%2F01%2Fp%2FLaravel5.x%E8%BF%9B%E9%98%B6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在浏览器中展示创建的Article列表在浏览器中展示创建的Article数据，需要使用Http请求Web服务器，Web服务器接收请求并将Article数据在视图页面中展示，即MVC。完成上述操作，离不开Laravel的路由功能，所谓路由就是请求的控制转发。Laravel把所有的请求地址预先配置在路由列表文件中learnlaravel5/app/Http/routes.php。描述路由的基本格式是： 1Route::get(&apos;/home&apos;, &apos;HomeController@index&apos;); Route类（\Illuminate\Support\Facades\Route）是Laravel框架提供的路由配置工具类，get标识http请求的Method（get/post/put/patch…），get函数的第一个参数是url格式定义，第二个参数用@分割成两部分，第一部分是Http请求的Controller类，第二部分标识Controller的具体执行方法，具体看HomeController类的内容描述： 123456789101112131415161718192021222324252627282930&lt;?phpnamespace App\Http\Controllers;use App\Article;use App\Http\Requests;use Illuminate\Http\Request;class HomeController extends \Illuminate\Routing\Controller&#123; /** * Create a new controller instance. * * @return void */ public function __construct() &#123; $this-&gt;middleware(&apos;auth&apos;); &#125; /** * Show the application dashboard. * * @return \Illuminate\Http\Response */ public function index() &#123; return view(&apos;home&apos;)-&gt;withArticles(Article::all());; &#125;&#125; _construct()是默认构造函数，函数体使用middleware(‘auth’)中间件，描述访问这个Controller需要登录验证。index()方法则是在路由中指定的执行方法，返回值是一个视图层对象view，视图的目录位置是模板文件learnlaravel5/resources/views/home.blade.php，view(‘home’)中的home与模板文件的第一个关键字相同，index函数指定了返回的视图文件，并把Article数据通过Eloquent方法取出，使用withArticles方法携带返回到视图页面，此处withArticles标识在页面可以通过articles对象取得所有返回的数据，依次类推如果是withAcls,则在页面上使用acls对象获取返回的数据。home.blade.php示例（php模板语法自行解决）： 12345678910111213141516171819202122232425@extends(&apos;layouts.app&apos;)@section(&apos;content&apos;) &lt;div id=&quot;title&quot; style=&quot;text-align: center;&quot;&gt; &lt;h1&gt;Learn Laravel 5&lt;/h1&gt; &lt;div style=&quot;padding: 5px; font-size: 16px;&quot;&gt;Learn Laravel 5&lt;/div&gt; &lt;/div&gt; &lt;hr&gt; &lt;div id=&quot;content&quot;&gt; &lt;ul&gt; @foreach ($articles as $article) &lt;li style=&quot;margin: 50px 0;&quot;&gt; &lt;div class=&quot;title&quot;&gt; &lt;a href=&quot;&#123;&#123; url(&apos;article/&apos;.$article-&gt;id) &#125;&#125;&quot;&gt; &lt;h4&gt;&#123;&#123; $article-&gt;title &#125;&#125;&lt;/h4&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;body&quot;&gt; &lt;p&gt;&#123;&#123; $article-&gt;body &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/li&gt; @endforeach &lt;/ul&gt; &lt;/div&gt;@endsection 通过浏览器输入http://localhost:1024/home，就能看到数据加载到页面。]]></content>
      <tags>
        <tag>PHP</tag>
        <tag>Laravel5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 5.x进阶笔记（一）]]></title>
    <url>%2F2017%2F08%2F01%2Fp%2FLaravel5.x%E8%BF%9B%E9%98%B6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[默认条件MacOS，&gt;=PHP5.4，翻墙环境（默认创建的项目会请求*.google.com）懂得PHP基础知识和MVC的基本架构，开发环境已经安装Laravel所需的命令环境。 配置composer中国镜像，使得本地开发环境下载依赖速度更快。1composer config -g repo.packagist composer https://packagist.phpcomposer.com 创建Laravel项目进入项目的工作空间目录 1cd ~/workspace 创建Laravel项目1composer -vvv create-project laravel/laravel learnlaravel5 5.2.31 项目创建完成，进入刚刚创建的项目，并使用PHP内置server服务启动项目，访问页面验证。 12cd learnlaravel5/publicphp -S 0.0.0.0:1024 页面效果使用1024端口访问的目的是Unix系统的动态端口的开始端口，不需要进行端口配置，就可以启动监听。如果单纯要学习Laravel或者PHP，请不要使用apache或者nginx这样的web服务器启动项目，对学习本身带来影响。 启用Laravel针对PHP5.4版本的trait特性实现用户注册登录的功能，实现简单的用户权限管理12cd .. ##cd ~/workspace/learnlaravel5php artisan make:auth 不需要停止php -S即可直接访问localhost:1024/login查看生成登录页面 Mysql创建数据库laravel5，用户名和密码均为root1create database laravel5 修改learnlaravel5项目的配置文件12cd ~/workspace/learnlaravel5open .env ##.env文件不存在，需要拷贝一份.env.example 修改配置项 123456DB_CONNECTION=mysqlDB_HOST=127.0.0.1DB_PORT=3306DB_DATABASE=laravel5DB_USERNAME=rootDB_PASSWORD=root 使用laravel默认的数据库描述文件创建表执行命令创建表 1php artisan migrate migrate命令要执行的php描述文件是learnlaravel5/database/migrations下的文件 2014_10_12_000000_create_users_table.php 2014_10_12_100000_create_password_resets_table.php再查看一下laravel5数据库中是否创建了这两个描述文件中的表，如果已经创建，说明命令执行成功，就可以用注册页面注册用户了，赶快试一试。使用 Laravel 的“葵花宝典”：EloquentEloquent是Laravel定义的Model基类，只要Larave创建Model就会继承Eloquent类，此时创建的Model就具有了十个异常强大的函数，从此想干啥事儿都是一行代码就搞定，创建一个Article的Model体验一下： 1php artisan make:model Article 创建Article对应的数据库描述文件 1php artisan make:migration create_article_table 打开刚刚创建的数据库迁移描述文件 1open learnlaravel5/database/migration/*_create_article_table.php 修改文件的内容为： 123456789101112131415161718192021222324252627282930313233343536&lt;?phpuse Illuminate\Database\Schema\Blueprint;use Illuminate\Database\Migrations\Migration;class CreateArticleTable extends Migration&#123; /** * Run the migrations. * * 创建文章表 * * @return void */ public function up() &#123; Schema::create(&apos;articles&apos;, function($table) &#123; $table-&gt;increments(&apos;id&apos;); $table-&gt;string(&apos;title&apos;); $table-&gt;text(&apos;body&apos;)-&gt;nullable(); $table-&gt;integer(&apos;user_id&apos;); $table-&gt;timestamps(); &#125;); &#125; /** * Reverse the migrations. * * @return void */ public function down() &#123; // &#125;&#125; 再次使用数据库迁移命令创建articles表 1php artisan migrate 执行完后，在laravel5的数据库中会创建出articles的表结构。使用Seeder往数据库中插入默认数据。首先创建一个Seeder，例如： 1php artisan make:seeder ArticleSeeder 在learnlaravel5/database/seeds/下打开并修改刚刚创建的ArticleSeeder.php文件，默认的run函数体为空，为其添加创建Article的数据脚本。 1234567891011public function run() &#123; DB::table(&apos;articles&apos;)-&gt;delete(); for ($i=0;$i&lt;10;$i++)&#123; \App\Article::create([ &apos;title&apos;=&gt;&apos;Title&apos;.$i, &apos;body&apos;=&gt;&apos;Body&apos;.$i, &apos;user_id&apos;=&gt;1 ]); &#125; &#125; 把ArticleSeeder注册到项目的数据库执行环境中。打开learnlaravel5/database/seeds/DatabaseSeeder.php，并修改run函数。 1234public function run() &#123; $this-&gt;call(ArticleSeeder::class); &#125; 由于learnlaravel5/database目录不能被composer自动加载，所有需要执行命令让这个目录加载待composer环境，保证代码能找到ArticleSeedr这个类。 1composer dump-autoload 然后再执行 1php artisan db:seed 执行完，此时在数据库laravel5的article表中会产生10条数据。 下一节再讲解如何展示插入的数据 &gt;&gt;&gt;Laravel 5.x进阶笔记（二）]]></content>
      <tags>
        <tag>PHP</tag>
        <tag>Laravel5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 5.x进阶笔记（二）]]></title>
    <url>%2F2017%2F08%2F01%2Fp%2FLaravel5.x%E8%BF%9B%E9%98%B6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"></content>
      <tags>
        <tag>PHP</tag>
        <tag>Laravel5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker清理命令]]></title>
    <url>%2F2017%2F05%2F21%2FDocker%E6%B8%85%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[杀死所有正在运行的容器 docker kill $(docker ps -a -q) 删除所有已经停止的容器 docker rm $(docker ps -a -q) 删除所有未打 dangling 标签的镜像 docker rmi $(docker images -q -f dangling=true) 删除所有镜像 docker rmi $(docker images -q) 为这些命令创建别名 ~/.bash_aliases COMMOND 杀死所有正在运行的容器. alias dockerkill=&#39;docker kill $(docker ps -a -q)&#39; 删除所有已经停止的容器. alias dockercleanc=&#39;docker rm $(docker ps -a -q)&#39; 删除所有未打标签的镜像. alias dockercleani=&#39;docker rmi $(docker images -q -f dangling=true)&#39; 删除所有已经停止的容器和未打标签的镜像. alias dockerclean=&#39;dockercleanc || true &amp;&amp; dockercleani&#39;]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
